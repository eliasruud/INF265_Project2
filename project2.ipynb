{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device cpu.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from datetime import datetime\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "device = (torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu'))\n",
    "print(f\"Device {device}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INF265 Project 2: Object Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Object localization tasks:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = 'data/localization_train.pt'\n",
    "val_path = 'data/localization_val.pt'\n",
    "test_path = 'data/localization_test.pt'\n",
    "\n",
    "train_data = torch.load(train_path)\n",
    "val_data = torch.load(val_path)\n",
    "test_data = torch.load(test_path)\n",
    "\n",
    "batch_size = 64\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=False)\n",
    "val_loader = torch.utils.data.DataLoader(val_data, batch_size=batch_size, shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "(batch, labels) = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.utils.data.dataset.TensorDataset'>\n",
      "Train data size:  59400\n",
      "Val data size:  6600\n",
      "Test data size:  11000\n",
      "torch.Size([1, 48, 60])\n",
      "torch.Size([1, 48, 60])\n",
      "tensor([1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 0., 1., 0.])\n"
     ]
    }
   ],
   "source": [
    "print(type(train_data))\n",
    "print(\"Train data size: \", len(train_data))\n",
    "print(\"Val data size: \", len(val_data))\n",
    "print(\"Test data size: \", len(test_data))\n",
    "print(train_data[0][0].shape)\n",
    "\n",
    "img= batch[0]\n",
    "print(img.shape)\n",
    "print(labels[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "img1, first_label = train_data[0]\n",
    "\n",
    "plt.imshow(img1.squeeze().numpy(), cmap='gray')\n",
    "print(first_label[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### My convolutional models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCNN1(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.cnn = nn.Sequential(\n",
    "\n",
    "            # Conv layer block 1\n",
    "            nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            \n",
    "            # Flatten the output to vector for the fully connected layer\n",
    "            nn.Flatten(),\n",
    "            \n",
    "            # FC layers\n",
    "            nn.Linear(32 * 24 * 30, 512),\n",
    "            nn.Linear(512, 15)  # 15 outputs, 1 Pc + 4 bounding box vars + 10 classes\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.cnn(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCNN2(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.cnn = nn.Sequential(\n",
    "\n",
    "            # Conv layer block 1\n",
    "            nn.Conv2d(in_channels=1, out_channels=32, kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            \n",
    "            # Conv layer block 2\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            \n",
    "            # Flatten the output to vector for the fully connected layer\n",
    "            nn.Flatten(),\n",
    "            \n",
    "            # FC layers\n",
    "            nn.Linear(64 * 12 * 15, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 15)  # 15 outputs, 1 Pc + 4 bounding box vars + 10 classes\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.cnn(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCNN3(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.cnn = nn.Sequential(\n",
    "\n",
    "            # Conv layer block 1\n",
    "            nn.Conv2d(in_channels=1, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            \n",
    "            # Conv layer block 2\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            # Conv layer block 3\n",
    "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            \n",
    "            # Flatten the output to vector for the fully connected layer\n",
    "            nn.Flatten(),\n",
    "            \n",
    "            # FC layers\n",
    "            nn.Linear(256 * 6 * 7, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 15)  # 15 outputs, 1 Pc + 4 bounding box vars + 10 classes\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.cnn(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uses different loss functions for different parts of the output.\n",
    "def localization_loss(y_pred, y_true):\n",
    "    \n",
    "    BCE_loss = nn.BCEWithLogitsLoss()\n",
    "    MSE_loss = nn.MSELoss()\n",
    "    CE_loss = nn.CrossEntropyLoss()\n",
    "\n",
    "  \n",
    "    La = BCE_loss(torch.sigmoid(y_pred[:, 0]), y_true[:, 0])      # Loss function for our detection output: 'Pc'.\n",
    "    Lb = MSE_loss(y_pred[:, 1:5], y_true[:, 1:5])                       # Loss function for our bounding box output: x, y, w, h.\n",
    "    Lc = CE_loss(y_pred[:, 5:], y_true[:, 5].long())                    # Loss function for our class output: c1, c2, c3 ... c10.\n",
    "\n",
    "    Pc = y_true[:, 0]\n",
    "    empty_tensor = torch.tensor(0.0).to(y_pred.device)\n",
    "\n",
    "    loss = La + torch.where(Pc == 1, La + Lb + Lc, empty_tensor) # Adds the Lb and Lc losses only if Pc is 1, otherwise adds the empty tensor.\n",
    "\n",
    "    return loss.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loss_fn, lr, n_epochs, train_loader): \n",
    "\n",
    "    n_batch = len(train_loader)\n",
    "    losses_train = []\n",
    "    model.train()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "\n",
    "        loss_train = 0.0\n",
    "        for i, data in enumerate(train_loader):\n",
    "\n",
    "            x = data[0].to(device=device) \n",
    "            y_true = data[1].to(device=device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            y_pred = model(x)\n",
    "\n",
    "            loss = loss_fn(y_pred, y_true)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            loss_train += loss.item()\n",
    "\n",
    "        losses_train.append(loss_train / n_batch)\n",
    "\n",
    "        print('{}  |  Epoch {} of {}  |  Training loss {:.5f}'.format(\n",
    "            datetime.now().time(), epoch, n_epochs, loss_train / n_batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------\n",
      "Currently training:  MyCNN1(\n",
      "  (cnn): Sequential(\n",
      "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Flatten(start_dim=1, end_dim=-1)\n",
      "    (4): Linear(in_features=23040, out_features=512, bias=True)\n",
      "    (5): Linear(in_features=512, out_features=15, bias=True)\n",
      "  )\n",
      ")\n",
      "----------------------------\n",
      "07:50:31.644220  |  Epoch 1  |  Training loss 2.75787\n",
      "07:52:15.070353  |  Epoch 2  |  Training loss 2.67572\n",
      "07:54:01.585544  |  Epoch 3  |  Training loss 2.59611\n",
      "07:55:46.033098  |  Epoch 4  |  Training loss 2.48041\n",
      "07:57:29.291155  |  Epoch 5  |  Training loss 2.35089\n",
      "----------------------------\n",
      "----------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----------------------------\n",
      "Currently training:  MyCNN2(\n",
      "  (cnn): Sequential(\n",
      "    (0): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): ReLU()\n",
      "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Flatten(start_dim=1, end_dim=-1)\n",
      "    (7): Linear(in_features=11520, out_features=256, bias=True)\n",
      "    (8): ReLU()\n",
      "    (9): Linear(in_features=256, out_features=15, bias=True)\n",
      "  )\n",
      ")\n",
      "----------------------------\n",
      "07:59:46.937163  |  Epoch 1  |  Training loss 2.77485\n",
      "08:02:03.121991  |  Epoch 2  |  Training loss 2.70271\n",
      "08:04:20.580925  |  Epoch 3  |  Training loss 2.55406\n",
      "08:06:36.298233  |  Epoch 4  |  Training loss 2.28421\n",
      "08:08:54.912139  |  Epoch 5  |  Training loss 2.07835\n",
      "----------------------------\n",
      "----------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----------------------------\n",
      "Currently training:  MyCNN3(\n",
      "  (cnn): Sequential(\n",
      "    (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): ReLU()\n",
      "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): ReLU()\n",
      "    (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (9): Flatten(start_dim=1, end_dim=-1)\n",
      "    (10): Linear(in_features=10752, out_features=512, bias=True)\n",
      "    (11): ReLU()\n",
      "    (12): Linear(in_features=512, out_features=15, bias=True)\n",
      "  )\n",
      ")\n",
      "----------------------------\n",
      "08:16:23.435806  |  Epoch 1  |  Training loss 2.78902\n",
      "08:24:13.053681  |  Epoch 2  |  Training loss 2.72689\n",
      "08:31:59.842043  |  Epoch 3  |  Training loss 2.55702\n",
      "08:39:55.093867  |  Epoch 4  |  Training loss 2.20209\n",
      "08:47:46.956374  |  Epoch 5  |  Training loss 1.98072\n",
      "----------------------------\n",
      "----------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "models = [MyCNN1(), MyCNN2(), MyCNN3()]\n",
    "\n",
    "lr = 0.005\n",
    "n_epochs = 5\n",
    "loss_fn = localization_loss\n",
    "\n",
    "for model in models:\n",
    "    print(\"----------------------------\")\n",
    "    print(\"Currently training: \", model)\n",
    "    print(\"----------------------------\")\n",
    "    train(model, loss_fn, lr, n_epochs, train_loader)\n",
    "\n",
    "    print(\"----------------------------\")\n",
    "    print(\"----------------------------\\n\\n\\n\")\n",
    "    print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_iou(pred_boxes, gt_boxes):\n",
    "\n",
    "    pred_boxes = pred_boxes.float()\n",
    "    gt_boxes = gt_boxes.float()\n",
    "    \n",
    "    # Calculate the coordinates of the intersection rectangles\n",
    "    x1 = torch.max(pred_boxes[:, 0], gt_boxes[:, 0])\n",
    "    y1 = torch.max(pred_boxes[:, 1], gt_boxes[:, 1])\n",
    "    x2 = torch.min(pred_boxes[:, 2], gt_boxes[:, 2])\n",
    "    y2 = torch.min(pred_boxes[:, 3], gt_boxes[:, 3])\n",
    "    \n",
    "    # Calculate intersection area\n",
    "    inter_area = torch.clamp(x2 - x1, min=0) * torch.clamp(y2 - y1, min=0)\n",
    "    \n",
    "    # Calculate the area of both prediction and ground truth boxes\n",
    "    pred_area = (pred_boxes[:, 2] - pred_boxes[:, 0]) * (pred_boxes[:, 3] - pred_boxes[:, 1])\n",
    "    gt_area = (gt_boxes[:, 2] - gt_boxes[:, 0]) * (gt_boxes[:, 3] - gt_boxes[:, 1])\n",
    "    \n",
    "    # Calculate the union area\n",
    "    union_area = pred_area + gt_area - inter_area\n",
    "    \n",
    "    # Calculate the IoU\n",
    "    iou = inter_area / union_area\n",
    "    \n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 6])\n",
      "torch.Size([6])\n",
      "tensor([ 7.2748, -0.1217,  1.9214,  5.0960,  4.9294,  2.3683,  2.0871,  3.1977,\n",
      "         2.8330,  2.6254,  2.0846,  1.8124,  3.4861,  1.7220,  4.8630,  2.3928,\n",
      "         1.4632,  4.2888,  1.0453,  2.8359,  2.5183,  3.1654,  1.0635,  4.5826,\n",
      "         1.9050,  2.7777,  2.5278,  5.2212,  4.6836,  4.0635,  5.3824,  3.7673,\n",
      "        -0.5406,  4.0735,  2.6532,  3.7840,  2.7444,  0.1742,  2.0202,  4.9920,\n",
      "         1.5056,  2.5759,  3.7132,  3.8764,  5.0151,  4.6158,  2.7759,  4.3476,\n",
      "         4.1491,  4.0125,  5.3803,  1.2441, -0.8776,  0.6744,  4.2997,  2.8566,\n",
      "         3.2157,  5.8529,  3.2682, -0.7949,  4.6902,  4.2847,  3.0222,  4.7143])\n",
      "SIGMOID:  tensor([], size=(0, 15))\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (15) must match the size of tensor b (64) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[148], line 39\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# Evaluate object presence accuracy\u001b[39;00m\n\u001b[0;32m     38\u001b[0m predicted_presence \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msigmoid(outputs[: \u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.5\u001b[39m  \u001b[38;5;66;03m# Assuming sigmoid output\u001b[39;00m\n\u001b[1;32m---> 39\u001b[0m object_presence_correct_predictions \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (predicted_presence \u001b[38;5;241m==\u001b[39m presence_labels)\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# Evaluate bounding box accuracy using IoU or similar\u001b[39;00m\n\u001b[0;32m     42\u001b[0m iou_scores \u001b[38;5;241m=\u001b[39m calculate_iou(outputs[:, \u001b[38;5;241m1\u001b[39m:\u001b[38;5;241m5\u001b[39m], bbox_labels)  \u001b[38;5;66;03m# Implement calculate_iou\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The size of tensor a (15) must match the size of tensor b (64) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "val_data\n",
    "val_loader\n",
    "\n",
    "performance = {}\n",
    "\n",
    "for i, model in enumerate(models):\n",
    "    model.eval()  # Ensure the model is in evaluation mode\n",
    "    total_loss = 0.0\n",
    "    classification_correct_predictions = 0\n",
    "    object_presence_correct_predictions = 0\n",
    "    total_iou = 0.0\n",
    "    total_predictions = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for input, labels in val_loader:\n",
    "            input = input.to(device)\n",
    "            # Assuming labels is a list or a custom object containing \n",
    "            # class labels, bounding boxes, and object presence\n",
    "            presence_labels = labels[:, 0].long().to(device)\n",
    "            bbox_labels = labels[:, 1:5].to(device)\n",
    "            class_labels = labels[:, 5].long().to(device)\n",
    "\n",
    "            outputs = model(input)  # Forward pass\n",
    "            \n",
    "            # Assuming outputs is a dict with keys 'classes', 'bboxes', and 'presence'\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # Evaluate classification accuracy\n",
    "            _, predicted_classes = torch.max(outputs[:, 5:].data, 1)\n",
    "            classification_correct_predictions += (predicted_classes == class_labels).sum().item()\n",
    "            print(labels.shape)\n",
    "            print(labels[0].shape)\n",
    "            print(outputs[:, 0])\n",
    "            #sig = torch.sigmoid(outputs[: 0])\n",
    "            #print(\"SIGMOID: \", sig)\n",
    "            # Evaluate object presence accuracy\n",
    "            predicted_presence = torch.sigmoid(outputs[: 0]).data > 0.5  # Assuming sigmoid output\n",
    "            object_presence_correct_predictions += (predicted_presence == presence_labels).sum().item()\n",
    "\n",
    "            # Evaluate bounding box accuracy using IoU or similar\n",
    "            iou_scores = calculate_iou(outputs[:, 1:5], bbox_labels)  # Implement calculate_iou\n",
    "            total_iou += iou_scores.sum().item()\n",
    "            \n",
    "            total_predictions += class_labels.size(0)\n",
    "\n",
    "        avg_loss = total_loss / len(val_loader)\n",
    "        classification_accuracy = classification_correct_predictions / total_predictions\n",
    "        presence_accuracy = object_presence_correct_predictions / total_predictions\n",
    "        avg_iou = total_iou / total_predictions\n",
    "        \n",
    "        print(f\"Validation Loss: {avg_loss:.4f}, Classification Accuracy: {classification_accuracy:.4f}, \"\n",
    "            f\"Presence Accuracy: {presence_accuracy:.4f}, Average IoU: {avg_iou:.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "# I sort by accuracy here.performance[i] = (avg_loss, accuracy)\n",
    "sorted_performance = sorted(performance.items(), key=lambda item: item[1][1], reverse=True)\n",
    "\n",
    "best_model = models[sorted_performance[0][0]] # I choose the model with the highest accuracy.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 6, 7, 8, 9]\n"
     ]
    }
   ],
   "source": [
    "lis = list(range(10))\n",
    "print(lis[5:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.eval()\n",
    "\n",
    "total_loss = 0\n",
    "correct_predictions = 0\n",
    "total_predictions = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for input, labels in test_loader:\n",
    "\n",
    "        input = input.to(device)  \n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        outputs = best_model(input)  #The forward pass\n",
    "        \n",
    "        loss = loss_fn(outputs, labels)\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total_predictions += labels.size(0)\n",
    "        correct_predictions += (predicted == labels).sum().item()\n",
    "\n",
    "    # Calculate average loss and total accuracy\n",
    "    avg_loss = total_loss / len(test_loader)\n",
    "    accuracy = correct_predictions / total_predictions\n",
    "    print(f\"Test Loss: {avg_loss:.4f}, Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.0000, 0.4000, 0.2188, 0.2667, 0.2292])\n"
     ]
    }
   ],
   "source": [
    "img, label = test_data[0]\n",
    "print(label[:-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drawing boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms.functional import to_pil_image\n",
    "from PIL import ImageDraw\n",
    "\n",
    "img, label = test_data[0]\n",
    "\n",
    "img_pil = to_pil_image(img)\n",
    "\n",
    "outputs = best_model(img)\n",
    "Pc1, x1, y1, w1, h1 = label[:5]\n",
    "Pc2, x2, y2, w2, h2 = outputs[:5]\n",
    "\n",
    "bbox_true = (x1, y1, x1 + w1, y1 + h1)\n",
    "bbox_pred = (x2, y2, x2 + w2, y2 + h2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "draw = ImageDraw.Draw(img_pil)\n",
    "draw.rectangle(bbox_true, outline=\"yellow\", width=3)\n",
    "draw.rectangle(bbox_pred, outline=\"red\", width=3)\n",
    "\n",
    "# Display the image\n",
    "img_pil.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Object detection tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_path = 'data/list_y_true_train.pt'\n",
    "#val_path = 'data/list_y_tru_val.pt'\n",
    "#test_path = 'data/list_y_tru_test.pt'\n",
    "\n",
    "train_path = 'data/detection_train.pt'\n",
    "val_path = 'data/detection_val.pt'\n",
    "test_path = 'data/detection_test.pt'\n",
    "\n",
    "train_data = torch.load(train_path)\n",
    "val_data = torch.load(val_path)\n",
    "test_data = torch.load(test_path)\n",
    "\n",
    "batch_size = 64\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=False)\n",
    "val_loader = torch.utils.data.DataLoader(val_data, batch_size=batch_size, shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyNewCNN1(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.cnn = nn.Sequential(\n",
    "\n",
    "            # Conv layer block 1\n",
    "            nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            \n",
    "            # Replaced layers\n",
    "            nn.Conv2d(in_channels=32, out_channels=15, kernel_size=1, stride=1, padding=0)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.cnn(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyNewCNN2(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.cnn = nn.Sequential(\n",
    "\n",
    "            # Conv layer block 1\n",
    "            nn.Conv2d(in_channels=1, out_channels=32, kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            \n",
    "            # Conv layer block 2\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            \n",
    "            # Replaced layers\n",
    "            nn.Conv2d(in_channels=64, out_channels=15, kernel_size=1, stride=1, padding=0)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.cnn(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyNewCNN3(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.cnn = nn.Sequential(\n",
    "\n",
    "            # Conv layer block 1\n",
    "            nn.Conv2d(in_channels=1, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            \n",
    "            # Conv layer block 2\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            # Conv layer block 3\n",
    "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            \n",
    "            # Replaced layers\n",
    "            nn.Conv2d(in_channels=256, out_channels=15, kernel_size=1, stride=1, padding=0)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.cnn(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [MyNewCNN1(), MyNewCNN2(), MyNewCNN3()]\n",
    "\n",
    "lr = 0.005\n",
    "n_epochs = 5\n",
    "loss_fn = localization_loss\n",
    "\n",
    "for model in models:\n",
    "    print(\"----------------------------\")\n",
    "    print(\"Currently training: \", model)\n",
    "    print(\"----------------------------\")\n",
    "    train(model, loss_fn, lr, n_epochs, train_loader)\n",
    "\n",
    "    print(\"----------------------------\")\n",
    "    print(\"----------------------------\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Draw boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "JUPYTER",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
